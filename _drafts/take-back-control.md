---
title: "Take back control"

---

In late 2016, I published my thesis on [algorithms as information gatekeepers](https://www.gitbook.com/book/tingeber/the-new-gatekeepers/details). Without going into the weeds (which you can totally do if you want to, you can [read it online](https://tingeber.gitbooks.io/the-new-gatekeepers/content/), download [PDF](https://www.gitbook.com/download/pdf/book/tingeber/the-new-gatekeepers)/[ePub](https://www.gitbook.com/download/epub/book/tingeber/the-new-gatekeepers)/[Mobi](https://www.gitbook.com/download/mobi/book/tingeber/the-new-gatekeepers), even [fork it on Github](https://github.com/tingeber/the-new-gatekeepers) if that's your jam), the paper analyses how information we are exposed to changes when human intermediaries (journalists) leave the gatekeeping to algorithms.

Now, this is a phenomenon that used to scare the beagles out of me — but in a rather abstract, “our conceptual paradigms are shifting” way.

Then Donald Trump happened.

Now there are lots of stories out there on how Facebook ruined it all for us. In my opinion, that is completely true. Simple, on the fly fact checking is not only possible, it’s easy to implement. But it doesn’t bring in clicks. Fake news are shared a lot; removing them from the platform would have caused shareholders to lose lots of moneymaking eyeballs. So Facebook hid behind a “neutrality of algorithms” rhetoric to justify a fundamentally immoral pollution of public opinion. And I will bet my Twitter follower count that Facebook already had solutions to the fake news problem, but it was never in their interest to turn them on.

There’s a lot of (academic, theoretical, exploratory) research about the ethical implication of algorithmic decision-making. The main focus though usually stays on the loss of choice, or at most on human bias interwoven in the algorithmic pattern. But the real danger, in the end, was corporate greed that was given the keys to the cognitive kingdom. In a race to the conceptual bottom, the most common social media platforms like Facebook reduce attention spans and engagement times with the only goal of maximising profit. And everyone plays along because that is the new normal. Like CBS chairman Les Moonves, who famously said that Trump is bad for America, but “[damn good for business](http://fortune.com/2016/03/01/les-moonves-cbs-trump/).”

## Algorithmic scapegoats

So where do algorithms come in? Are they just a scapegoat, a convenient straw-man for the “not my fault” crowd? Is the loss of signal in the sea of noise an inevitable, ironic result of relinquishing control over what is information versus what is garbage to automated systems that are absolutely alien to our understanding of quality and importance? 

No. Algorithms are an inevitable byproduct of an unprecedented amount of info-bombardment. We need tools to make sense of it all. But that is all algorithms are — tools for us to use or misuse. And oh boy have we been misusing them.

We let white, rich, western men exclusively control the production of algorithms. We let corporate mentality choose what is important for us. We legally forbid anyone to actually peek under the hood of how algorithmic choices are made. We came to live in a society where information filters are skewed, top-heavy, and elitist; where most of the population isn’t represented, where advertisers can filter by race, where religious views of a single country impose their views of decency to the entire globe. [We taught our machines to discriminate](http://www.fordfoundation.org/ideas/equals-change-blog/posts/can-computers-be-racist-big-data-inequality-and-discrimination/).


## We have to take back control 

It doesn’t have to be this way. We can demand control. But first we have to understand we lost it. We have to start understanding that there’s a veil of algorithmic mystery inches from our eyes. We have become used to relying on the perceived credibility of algorithmically-driven platforms to provide fact-checked and truthful information. Well now at least it’s clear nothing of the sort is actually happening.

- Give money to journalists
- Demand quality
- Common claims need common proof. Extraordinary claims need extraordinary proof
- If it’s too good to be true, it’s not true
- In most cases, 10 seconds on Google is all the fact-checking you need
- Don’t trust anyone
- Build a bomb shelter
